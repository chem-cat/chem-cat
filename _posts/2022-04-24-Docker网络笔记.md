---
layout: mypost
title: Docker网络笔记
categories: [Docker Linux]
---

*#音量注意：没有调节音量的功能，播放前请注意设备音量*

<iframe src="//music.163.com/outchain/player?type=2&id=1359818052&auto=1&height=66" frameborder="0" width="100%" height="86px" ></iframe>


## 序

> 网桥(network bridge)是由 Linux 内核提供的一种链路层设备，用于在不同网段之间转发数据包。Docker 就是利用网桥来实现容器和外界之间的通信的。默认情况下，Docker 服务会在它所在的机器上创建一个名为 docker0 的网桥。

## 安装 Docker

1. 查看内核版本，3.10 以上支持 Docker

   ```bash
   > # uname -r
   5.10.16.3-microsoft-standard-WSL2
   ```

2. 查看操作系统版本

   ```bash
   > # cat /etc/os-release
   NAME="Ubuntu"
   VERSION="20.04.3 LTS (Focal Fossa)"
   ID=ubuntu
   ID_LIKE=debian
   PRETTY_NAME="Ubuntu 20.04.3 LTS"
   VERSION_ID="20.04"
   HOME_URL="https://www.ubuntu.com/"
   SUPPORT_URL="https://help.ubuntu.com/"
   BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
   PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
   VERSION_CODENAME=focal
   UBUNTU_CODENAME=focal
   ```

3. 换源加快下载速度

   ```bash
   sudo vim /etc/apt/sources.list
   ```

   加入下列清华源

   ```sh
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse
   deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse
   deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse
   deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse
   deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse
   deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse
   ```

4. 更新软件包索引

   ```bash
   sudo apt update
   #更新
   sudo apt upgrade
   ```

5. 导入源仓库的 GPG key：

   ```bash
   curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
   ```

   添加 Docker APT 软件源

   ```bash
   sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
   ```

   

6. 安装 Docker 最新版本，右下角可以看到速度还是可以的

   ```bash
   sudo apt install docker-ce docker-ce-cli containerd.io
   ```

   ![Docker1.png](https://gcore.jsdelivr.net/gh/chem-cat/image-repo@main//20220501183659.png)

7. 启动 Docker 服务

   ```bash
   service docker start
   ```

8. 运行 hello-world 检查是否成功安装，打印出了打印出 “Hello from Docker”。

   ```bash
   sudo docker run hello-world
   ```

   ![Docker2.png](https://gcore.jsdelivr.net/gh/chem-cat/image-repo@main//Docker2.png)

9. 查看版本及镜像列表

   ```
   docker version
   docker images
   ```

   ![image-20220501184814835](https://gcore.jsdelivr.net/gh/chem-cat/image-repo@main//image-20220501184814835.png)

## Docker 网络

![img](https://gcore.jsdelivr.net/gh/chem-cat/image-repo@main//20201022150124588.png)

### 什么是 Docker0

首先，查看本地 IP

```bash
> # ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
4: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:15:5d:fe:f3:ad brd ff:ff:ff:ff:ff:ff
    inet 172.20.254.75/20 brd 172.20.255.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::215:5dff:fefe:f3ad/64 scope link
       valid_lft forever preferred_lft forever
7: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:d0:fd:ee:a9 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
```

启动 Docker 服务后，出现了一个 docker0 的虚拟网卡，这是一个用了 veth-pair 技术的桥接网卡。以下内容来自于MornigSpace的这篇文章[Kubernetes网络篇——从docker0开始](https://morningspace.github.io/tech/k8s-net-docker0/)，很详细地阐述了网桥在容器通信中期的作用。

docker0是由Docker服务在启动时自动创建出来的以太网桥。默认情况下，所有Docker容器都会连接到docker0，然后再通过这个网桥来实现容器和外界之间的通信。那么，Docker具体是怎么做到这一点的呢？我们先用`docker network ls`命令来看一下Docker默认提供的几种网络：

```
$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
d307261937e9        bridge              bridge              local
9a4e6a25b62e        host                host                local
53cf3a3b2e4f        none                null                local
```

我们知道，Docker容器在启动时，如果没有显式指定加入任何网络，就会默认加入到名为bridge的网络。而这个bridge网络就是基于docker0实现的。

除此以外，这里的host和none是有特殊含义的。其中，加入host网络的容器，可以实现和Docker daemon守护进程（也就是Docker服务）所在的宿主机网络环境进行直接通信；而none网络，则表示容器在启动时不带任何网络设备。

### 启动第一个容器

现在，我们就来看一下Docker容器在加入bridge网络的过程中，容器以及宿主机网络设置的变化情况。首先，我们通过`docker network inspect`命令，看一下bridge网络目前的状态：

```
$ docker network inspect bridge
[
    {
        "Name": "bridge",
        "Id": "d307261937e987e9a0d46279c2033824920167f31f1b0371a9f7dfc52b9e55ca",
        "Scope": "local",
        "Driver": "bridge",
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.17.0.0/16"
                }
            ]
        },
        "Containers": {},
        ... ...
    }
]
```

我们注意到，`Subnet`字段的值为172.17.0.0/16。这表明了，bridge网络位于172.17.0.0网段，子网掩码为255.255.0.0。这和前面`ifconfig`命令看到的结果保持一致，docker0的IP地址刚好位于这一网段内。

对`172.17.0.0/16`这种写法感到陌生的同学，可以在网上搜一下CIDR。这是一种被称为“无类域间路由”的标记方法，其英文全称为Classless Inter-Domain Routing（简称CIDR）。这个名字听起来有点唬人，不过没关系，我们只要记住，“/”前面的部分代表当前网段的网络ID，“/”后面的部分代表子网掩码中连续1的个数。比如，在我们的例子里，16就表示连续16个1，对应的子网掩码就是：`11111111.11111111.00000000.00000000`，十进制表示就是：`255.255.0.0`。

另外，我们还注意到，这里的`Containers`字段目前是空的。接下来，我们启动一个新的Docker容器：

```
$ docker run -dit --name busybox1 busybox sh
Unable to find image 'busybox:latest' locally
latest: Pulling from library/busybox
ff5eadacfa0b: Pull complete 
Digest: sha256:c888d69b73b5b444c2b0bd70da28c3da102b0aeb327f3a297626e2558def327f
Status: Downloaded newer image for busybox:latest
4710242fd42dc97b8f36470ceb8a29c32979a60f00cccc8d55edcab04216d6d3
```

可以看到，Docker为我们在当前宿主机上启动了一个名为busybox1的容器。这个时候，再查看bridge网络：

```
$ docker network inspect bridge
[
    {
        "Name": "bridge",
        "Id": "d307261937e987e9a0d46279c2033824920167f31f1b0371a9f7dfc52b9e55ca",
        "Scope": "local",
        "Driver": "bridge",
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.17.0.0/16"
                }
            ]
        },
        "Containers": {
            "4710242fd42dc97b8f36470ceb8a29c32979a60f00cccc8d55edcab04216d6d3": {
                "Name": "busybox1",
                "EndpointID": "2c82c71f3dc5b34e283c7f72c300912ce0f0e11890e7570c0b72bc748a5c1184",
                "MacAddress": "02:42:ac:11:00:02",
                "IPv4Address": "172.17.0.2/16",
                "IPv6Address": ""
            }
        },
        ... ...
    }
]
```

就会发现，`Containers`字段里出现了busybox1，也就是我们刚刚启动的那个容器。这说明busybox1容器已经成功地加入到了我们的bridge网络里。如果这个时候查看docker0网桥：

```
$ brctl show
bridge name	bridge id		STP enabled	interfaces
docker0		8000.024277d8e553	no		vethe657f66
```

就会发现，和一开始执行`brctl show`的输出结果相比，`interfaces`字段的位置多了一个名叫vethe657f66的网络接口。实际上，这是一种虚拟以太网设备(Virtual Ethernet Device，简称veth)。确切地说，这不是一个设备，而是一对设备，所以也被称为“veth pair”。它包含两个总是成对出现的网络接口，分别连接不同的network namespace。一端的网络接口接收到数据以后，就会立刻传送给另一端，从而在两个network namespace之间建立起了一个“通道”，实现了彼此之间的网络连通。通常，这一对接口本身并不会被分配IP地址。在我们的例子里，这个veth pair的一端位于容器busybox1里，另一端则位于宿主机上，也就是这里的vethe657f66。执行`ip addr show`命令查看该接口的详细信息：

```
$ ip addr show vethe657f66
6: vethe657f66@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default 
    link/ether 1a:e1:8a:b5:d3:93 brd ff:ff:ff:ff:ff:ff link-netnsid 1
```

可以看到，vethe657f66后面跟着一个后缀@if5。其中的数字5，代表了作为这个veth pair的另一端（即位于busybox1容器里的那个网络接口）在对应的network namespace里所有网络接口中的位置序号。也就是每当我们执行`ip addr show`命令的时候，输出结果里每个网络接口前面的那个数字。如果我们在busybox1里执行`ip addr show`：

```
$ docker exec busybox1 ip addr show
... ...
5: eth0@if6: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue 
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
```

就可以看到，eth0的序号正是5，和宿主机里vethe657f66后面的@if5是一致的。与此同时，busybox1里eth0的后缀是@if6。对照前面vethe657f66的输出结果，它的序号正是6。这说明，宿主机里的vethe657f66和busybox1里的eth0构成了一对veth pair。利用这个“通道”，我们的busybox1就可以实现和外界的通信了。

### 启动另一个容器

接下来，我们再来启动另一个容器：

```
$ docker run -dit --name busybox2 busybox sh
fa6c607330b5cf06753e86e89b0fa7c9620e7187a4905a67c07499fdc477d4c2
```

然后，查看bridge网络：

```
$ docker network inspect bridge
[
    {
        "Name": "bridge",
        "Id": "d307261937e987e9a0d46279c2033824920167f31f1b0371a9f7dfc52b9e55ca",
        "Scope": "local",
        "Driver": "bridge",
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.17.0.0/16"
                }
            ]
        },
        "Containers": {
            "4710242fd42dc97b8f36470ceb8a29c32979a60f00cccc8d55edcab04216d6d3": {
                "Name": "busybox1",
                "EndpointID": "2c82c71f3dc5b34e283c7f72c300912ce0f0e11890e7570c0b72bc748a5c1184",
                "MacAddress": "02:42:ac:11:00:02",
                "IPv4Address": "172.17.0.2/16",
                "IPv6Address": ""
            },
            "fa6c607330b5cf06753e86e89b0fa7c9620e7187a4905a67c07499fdc477d4c2": {
                "Name": "busybox2",
                "EndpointID": "2980a88338acb0b07ea4deb1e5a25d0264ece9fb16c5a8386469e853a101684a",
                "MacAddress": "02:42:ac:11:00:03",
                "IPv4Address": "172.17.0.3/16",
                "IPv6Address": ""
            }
        },
        ... ...
    }
]
```

可以看到，每次启动新的容器，默认总是会加入到这个bridge网络里的。现在的`Containers`字段，已经包含两个容器了，分别是busybox1和busybox2。我们还可以继续查看docker0网桥，以及veth pair分别在宿主机和容器里的网络接口信息，这里就不再赘述了。

### 验证网络连通性

这个时候，如果我们分别在宿主机和两个容器里执行ping命令，会发现它们三者是彼此连通的。比如，在宿主机里可以ping通容器：

```
$ ping 172.17.0.2 -c 3
PING 172.17.0.2 (172.17.0.2): 56 data bytes
64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.125 ms
64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.175 ms
64 bytes from 172.17.0.2: seq=2 ttl=64 time=0.194 ms

--- 172.17.0.2 ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.125/0.164/0.194 ms
```

在容器里可以ping通宿主机：

```
$ docker exec busybox1 ping 172.17.0.1 -c 3
PING 172.17.0.1 (172.17.0.1): 56 data bytes
64 bytes from 172.17.0.1: seq=0 ttl=64 time=0.090 ms
64 bytes from 172.17.0.1: seq=1 ttl=64 time=0.147 ms
64 bytes from 172.17.0.1: seq=2 ttl=64 time=0.162 ms

--- 172.17.0.1 ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.090/0.133/0.162 ms
```

也可以ping通其他容器：

```
$ docker exec busybox1 ping 172.17.0.3 -c 3
PING 172.17.0.3 (172.17.0.3): 56 data bytes
64 bytes from 172.17.0.3: seq=0 ttl=64 time=0.513 ms
64 bytes from 172.17.0.3: seq=1 ttl=64 time=0.533 ms
64 bytes from 172.17.0.3: seq=2 ttl=64 time=0.238 ms

--- 172.17.0.3 ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.238/0.428/0.533 ms
```

## 唠叨环节

2022年3月21日，14：20 广州机场雷达显示东航 MU5735 “偏离指令高度”，工作人员呼叫机组后未回应。14：21 雷达记录下飞机最后的信息：高度3380米，地速1010千米/小时，航向117度。随后失去信号。

明天不是一定会到来的。那些想要去见一见的人，和想要说出口的爱，都要趁早。

“拥抱吧，趁现在。”

## TODO LIST

1. k8s

## 参考

[Docker教程](https://www.bilibili.com/video/BV1og4y1q7M4?p=34)

[Kubernetes网络篇——从docker0开始](https://morningspace.github.io/tech/k8s-net-docker0/)
